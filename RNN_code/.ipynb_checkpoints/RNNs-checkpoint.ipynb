{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the filtered Shakespeare data \n",
    "file = open('./data/shakespeare_filt_2.txt', 'r')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the text into sequences of length characters, starting at every nth character \n",
    "length = 41\n",
    "n = 1\n",
    "sequences = [] \n",
    "\n",
    "for i in range(length, len(text), n):\n",
    "    seq = text[i-length:i+1]\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all the unique characters in seq_text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Creating a mapping for each unique char to an integer\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "reverse_mapping = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Size of the dictionary\n",
    "vocab_size = len(mapping)\n",
    "\n",
    "encoded_sequences = []\n",
    "# For every line in sequences, encode the sequences using the mapping\n",
    "for seq in sequences:\n",
    "    encoded_seq = [mapping[char] for char in seq]\n",
    "    encoded_sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93441, 41, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sequences into X and y\n",
    "encoded_sequences = array(encoded_sequences)\n",
    "X, y = encoded_sequences[:,:-1], encoded_sequences[:,-1]\n",
    "\n",
    "# Use to_categorical to one hot encode the sequences\n",
    "encoded_sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "\n",
    "# Use to_categorical to one hot encode y\n",
    "X = array(encoded_sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN model with # LSTM units (units) and temperature (temp)\n",
    "def generate_model(X, units, temp):\n",
    "    model = Sequential()\n",
    "    # LSTM \n",
    "    model.add(LSTM(units, input_shape=(X.shape[1], X.shape[2])))\n",
    "    \n",
    "    # Add Lambda layer with temperature parameter \n",
    "    model.add(Lambda(lambda x: x / temp))\n",
    "    \n",
    "    # Softmax layer \n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 155)               119040    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 155)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                5616      \n",
      "=================================================================\n",
      "Total params: 124,656\n",
      "Trainable params: 124,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " - 95s - loss: 2.4592 - accuracy: 0.2968\n",
      "Epoch 2/50\n",
      " - 86s - loss: 2.0959 - accuracy: 0.3801\n",
      "Epoch 3/50\n",
      " - 93s - loss: 1.9726 - accuracy: 0.4095\n",
      "Epoch 4/50\n",
      " - 89s - loss: 1.8881 - accuracy: 0.4326\n",
      "Epoch 5/50\n",
      " - 90s - loss: 1.8247 - accuracy: 0.4495\n",
      "Epoch 6/50\n",
      " - 88s - loss: 1.7763 - accuracy: 0.4605\n",
      "Epoch 7/50\n",
      " - 88s - loss: 1.7356 - accuracy: 0.4709\n",
      "Epoch 8/50\n",
      " - 94s - loss: 1.7014 - accuracy: 0.4783\n",
      "Epoch 9/50\n",
      " - 92s - loss: 1.6724 - accuracy: 0.4872\n",
      "Epoch 10/50\n",
      " - 100s - loss: 1.6458 - accuracy: 0.4926\n",
      "Epoch 11/50\n",
      " - 94s - loss: 1.6226 - accuracy: 0.5000\n",
      "Epoch 12/50\n",
      " - 86s - loss: 1.6019 - accuracy: 0.5055\n",
      "Epoch 13/50\n",
      " - 86s - loss: 1.5802 - accuracy: 0.5121\n",
      "Epoch 14/50\n",
      " - 118s - loss: 1.5743 - accuracy: 0.5126\n",
      "Epoch 15/50\n",
      " - 86s - loss: 1.5541 - accuracy: 0.5194\n",
      "Epoch 16/50\n",
      " - 87s - loss: 1.5198 - accuracy: 0.5311\n",
      "Epoch 17/50\n",
      " - 86s - loss: 1.4990 - accuracy: 0.5373\n",
      "Epoch 18/50\n",
      " - 86s - loss: 1.4859 - accuracy: 0.5393\n",
      "Epoch 19/50\n",
      " - 88s - loss: 1.4711 - accuracy: 0.5436\n",
      "Epoch 20/50\n",
      " - 94s - loss: 1.4547 - accuracy: 0.5482\n",
      "Epoch 21/50\n",
      " - 99s - loss: 1.4409 - accuracy: 0.5523\n",
      "Epoch 22/50\n",
      " - 93s - loss: 1.4267 - accuracy: 0.5553\n",
      "Epoch 23/50\n",
      " - 90s - loss: 1.4146 - accuracy: 0.5593\n",
      "Epoch 24/50\n",
      " - 90s - loss: 1.4008 - accuracy: 0.5629\n",
      "Epoch 25/50\n",
      " - 93s - loss: 1.3899 - accuracy: 0.5668\n",
      "Epoch 26/50\n",
      " - 91s - loss: 1.3764 - accuracy: 0.5701\n",
      "Epoch 27/50\n",
      " - 89s - loss: 1.3652 - accuracy: 0.5729\n",
      "Epoch 28/50\n",
      " - 88s - loss: 1.3531 - accuracy: 0.5769\n",
      "Epoch 29/50\n",
      " - 90s - loss: 1.3424 - accuracy: 0.5810\n",
      "Epoch 30/50\n",
      " - 90s - loss: 1.3318 - accuracy: 0.5827\n",
      "Epoch 31/50\n",
      " - 94s - loss: 1.3205 - accuracy: 0.5869\n",
      "Epoch 32/50\n",
      " - 99s - loss: 1.3102 - accuracy: 0.5904\n",
      "Epoch 33/50\n",
      " - 91s - loss: 1.2993 - accuracy: 0.5926\n",
      "Epoch 34/50\n",
      " - 92s - loss: 1.2890 - accuracy: 0.5950\n",
      "Epoch 35/50\n",
      " - 87s - loss: 1.2772 - accuracy: 0.5992\n",
      "Epoch 36/50\n",
      " - 87s - loss: 1.2688 - accuracy: 0.6016\n",
      "Epoch 37/50\n",
      " - 105s - loss: 1.2588 - accuracy: 0.6052\n",
      "Epoch 38/50\n",
      " - 105s - loss: 1.2476 - accuracy: 0.6082\n",
      "Epoch 39/50\n",
      " - 123s - loss: 1.2384 - accuracy: 0.6098\n",
      "Epoch 40/50\n",
      " - 92s - loss: 1.2280 - accuracy: 0.6148\n",
      "Epoch 41/50\n",
      " - 92s - loss: 1.2197 - accuracy: 0.6168\n",
      "Epoch 42/50\n",
      " - 92s - loss: 1.2092 - accuracy: 0.6192\n",
      "Epoch 43/50\n",
      " - 104s - loss: 1.2001 - accuracy: 0.6235\n",
      "Epoch 44/50\n",
      " - 116s - loss: 1.1920 - accuracy: 0.6246\n",
      "Epoch 45/50\n",
      " - 111s - loss: 1.1837 - accuracy: 0.6278\n",
      "Epoch 46/50\n",
      " - 105s - loss: 1.1745 - accuracy: 0.6314\n",
      "Epoch 47/50\n",
      " - 111s - loss: 1.1655 - accuracy: 0.6329\n",
      "Epoch 48/50\n",
      " - 90s - loss: 1.1572 - accuracy: 0.6348\n",
      "Epoch 49/50\n",
      " - 90s - loss: 1.1477 - accuracy: 0.6376\n",
      "Epoch 50/50\n",
      " - 98s - loss: 1.1412 - accuracy: 0.6397\n"
     ]
    }
   ],
   "source": [
    "# I ran this cell multiple times with different parameters and saved the models \n",
    "model = generate_model(X,155,2.020)\n",
    "model.fit(X, y, epochs=50, verbose=2)\n",
    "model.save('./data/model_1_155_2.020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Generate a sequence of words given a seed\n",
    "def generate_seq(model, mapping, reverse_mapping, length, seed, n_chars):\n",
    "    text = seed\n",
    "     \n",
    "    for i in range(n_chars):\n",
    "        # Encode the characters \n",
    "        encoded = [mapping[char] for char in text]\n",
    "        \n",
    "        # Fixes the length of the sequence to be max length \n",
    "        encoded = pad_sequences([encoded], maxlen=length, truncating='pre')\n",
    "        \n",
    "        # Hot one encode the sequence\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        \n",
    "        # Predict the characters \n",
    "        prediction = model.predict_classes(encoded, verbose=0)\n",
    "        \n",
    "        # Map the index to a character using reverse_mapping\n",
    "        out_char = reverse_mapping[prediction[0]]\n",
    "        text += out_char\n",
    "        \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 150)               112200    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                5436      \n",
      "=================================================================\n",
      "Total params: 117,636\n",
      "Trainable params: 117,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "o his coorule ill but that should i le press.\n",
      "andeare thou make those didsicchestee even.\n",
      "for strat apon you wear agt of briends same,\n",
      "now forter oubless stall and mo gove willoss\n",
      "by ghard, and moren enderted theidespreed,\n",
      "which which it by strang time inas it be\n",
      "against pface thee alt the world waskemed,\n",
      "with a partyore dospiny, and praise resing,\n",
      "and to gove from thee hawh yot the stare,\n",
      "and mine eye withose forment, soull can than you keed,\n",
      "the rether self the fliedous refover all,\n",
      "i seaun to thee doth thy self that shane,\n",
      "in their beduey's but to thee shall nome,\n",
      "the love and to be tire bus bute, love.\n",
      "then love to be mys bett call one, of the elsect.\n",
      "i sweet wauty of hame anon thee my leats\n",
      "in ever ad all her far the will, and\n",
      "at mostilltedearest have in lake tome and.\n",
      "my glade they desired passinds is will best,\n",
      "that is is stookent deap sammer the erent.\n",
      "soulity sece a alt the blest hath my need,\n",
      "for they which thou mest thou distist true\n",
      "mink an my mort ter'sings and all,\n",
      "and al\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_4_150_1.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 150)               112200    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                5436      \n",
      "=================================================================\n",
      "Total params: 117,636\n",
      "Trainable params: 117,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "the reeves be their partion one time,\n",
      "thou art the bare's fore thee i joy not,\n",
      "the other with all withing of wormest lie,\n",
      "me is sight thee to foull far fre-how,\n",
      "the one than in me despyest with self bridg\n",
      "as with the cen ofe though i praise the brow,\n",
      "then will for my love, that to worth in ackil,\n",
      "a though i have so shall i am from me.\n",
      "let to hime for cares make of me love pose,\n",
      "when i beholy quesing were simes and detay.\n",
      "o true all for thee is a dail consing,\n",
      "and no not sagming acpiving wore your sead,\n",
      "still see wo love that i do you your seeming thee.\n",
      "when i have see i breast the tyolly are,\n",
      "and thou witt the best, show make flownrseds?\n",
      "in sill-lllame love he carouble sain gill\n",
      "artay hath erse his lifferce again is raie,\n",
      "that i am he dead, to decherse when chueks\n",
      "o no expurn if the world ever bear,\n",
      "surter the beauty of see, do no foor haig\n",
      "thou thy self than glest of my refight,\n",
      "and the culls of and true, his in his hals,\n",
      "that i am for my self are receives begivest,\n",
      "when i am he dear \n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_2_100_1.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 100)               54800     \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 36)                3636      \n",
      "=================================================================\n",
      "Total params: 58,436\n",
      "Trainable params: 58,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "thy will not me thou be receiv'st of my more,\n",
      "that i have sweet fair this sweet upon thee,\n",
      "do works that which i constanter's shape,\n",
      "the world not so thou be received and thee\n",
      "were his black sweet fair with his charace\n",
      "but thou dost thou art swears of thy self,\n",
      "and thou shall summord of their fair frows,\n",
      "and so not love hath thoughts (and sinceed\n",
      "but her preature that my love to the wrong,\n",
      "that i have sweet fair those as my sins mind,\n",
      "that strongle and then my love still still,\n",
      "that i have sweet think that thou art so grows,\n",
      "so live thou art swearous will best sight,\n",
      "then thy sweet self compovion spent\n",
      "she live thy self in their shame do in mend,\n",
      "nor cannit is not so great doth thought,\n",
      "and love's fire his black have summer'st the grow,\n",
      "to live thee that thou art so death of thy brow,\n",
      "for i not love thy self in their bear weak,\n",
      "to leave thou art sworn, which i my love thee,\n",
      "which i being my state which i constant deeds,\n",
      "the subject to the world with thy self doth repay,\n",
      "and the world w\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_1_100_1.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100)               54800     \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 36)                3636      \n",
      "=================================================================\n",
      "Total params: 58,436\n",
      "Trainable params: 58,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "thou thy self and some thee that thou art,\n",
      "and that i am thou art so fair praised than\n",
      "thou art the world my love that beauty of me,\n",
      "and that thou art the world my self to tell.\n",
      "and the world of more that in the world,\n",
      "and the strength in my self all the worth and love,\n",
      "that i am thou art summer and the sum,\n",
      "when i and beauty be thre beauted, and.\n",
      "thou art the world men of the substare told,\n",
      "and then still the world of thee that i am,\n",
      "to the present on thou art so all tree,\n",
      "that thou art the world my love thou art,\n",
      "and that thou art the world my self all tords of sin,\n",
      "that i am thou art summer and the stand\n",
      "and thou art the present of the than thought, than thou art summer's lasse thee,\n",
      "and then thou art the world my self all thee,\n",
      "and the presents and the love thee the wort,\n",
      "that thou art the world men of thee thee,\n",
      "and that thou art the world my self all tords of sin,\n",
      "that i am thou art summer and the stand\n",
      "and thou art the present of the than thought, than thou art summer's lasse th\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_1_100_1.50.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100)               54800     \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 36)                3636      \n",
      "=================================================================\n",
      "Total params: 58,436\n",
      "Trainable params: 58,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "whence sweet self thou art as the seen thee,\n",
      "who art as thou art forgot in truth desert,\n",
      "and in the will every what i seen thee,\n",
      "and in the will all-earies the strong,\n",
      "for thou art forgot, than thou art as mine,\n",
      "so that i have thought the day of thee in me,\n",
      "whaten i am so thine the return of thy show,\n",
      "the one doth that words which shall state,\n",
      "and then i am so greate to canchy which string,\n",
      "and their still with my aming make to thee,\n",
      "the olk your then thou wast ten undo steres,\n",
      "they have the willies and straight in thee,\n",
      "when thou whose shall see his gract a good.\n",
      "thou art as thou art beauty on the disgrace.\n",
      "lest thou art thou that i am as thy carrons,\n",
      "then shall shame is beauty of the thought,\n",
      "and heart's for my sing the chourd thee frest,\n",
      "that thou art all thought the dial how thee.\n",
      "if that in the winter stains words to grait\n",
      "for thee the world with the proud thee steep,\n",
      "the one another seem but every hand\n",
      "with men to the blessed with from my stain,\n",
      "and then should be thee in the wil\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_1_100_0.75.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 100)               54800     \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 36)                3636      \n",
      "=================================================================\n",
      "Total params: 58,436\n",
      "Trainable params: 58,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "thou are you with me ablacked that love told\n",
      "still to hear that which i think of thine,\n",
      "and such a breath, and to my dear pleasure.\n",
      "so thee, thou dost not be thy dear fair render,\n",
      "whilst thou art forgot, where beauty being,\n",
      "and to the resto disgrace,\n",
      "but when i summer's breathers beauty maken\n",
      "which works my love to store summer of you,\n",
      "and love another than with the beauty,\n",
      "and see to summer's death thou art offend\n",
      "those than they truthful worly is strongf dead.\n",
      "but when from thee that i have sun of live?\n",
      "why should the best that i will be then say,\n",
      "and for the sorry the world, thought in thy fixest pride.\n",
      "o that bear thy self-sowng to me,\n",
      "nor dare i have i should i womb they sin,\n",
      "as what so for some of time's with the doth fair shall be tongue,\n",
      "and praise that thou art to growned by\n",
      "againtied to the restill grow heart.\n",
      "and you trimment thou that which i will dross,\n",
      "when i swear any will by thy deeds,\n",
      "and thence is such appetith thee,\n",
      "and to the strength not that i will best\n",
      "away to co\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_1_100_0.25.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 155)               119040    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 155)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                5616      \n",
      "=================================================================\n",
      "Total params: 124,656\n",
      "Trainable params: 124,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "shall i compare thee to a summer's day?\n",
      "thou art the proud charve lived that they deeds,\n",
      "and the world make the world will i must,\n",
      "but that i age of the world my self dissiged,\n",
      "and that i an the world my self dothed,\n",
      "and that thou art a somethered thee,\n",
      "and i am the world may still that thou art,\n",
      "and that i am the world may strange, the strange,\n",
      "the worst that thou art a somethered theme\n",
      "but then see the world my heart that thou hast eyes,\n",
      "and more beauty shall be the shade shouldse,\n",
      "and to the world my self art the world,\n",
      "and single of thy self thou art sweet self,\n",
      "and the world may still that thou art a sod,\n",
      "the part i conder breath with the sun in grace,\n",
      "and that thou art a somethered the deared,\n",
      "and then do the oured have i am the strange,\n",
      "thy self are the world may still that thou sumper, and see, doth give\n",
      "as the strange my love shall be seen strong,\n",
      "that thou art a somethered the most prove,\n",
      "thee from the world my self are the world,\n",
      "and the contented though thy self and those.\n",
      "so thou thy self and thought i love thee\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./data/model_1_155_2.020.h5')\n",
    "print(model.summary())\n",
    "print(generate_seq(model, mapping, reverse_mapping, 41, \"shall i compare thee to a summer's day?\\n\", 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
